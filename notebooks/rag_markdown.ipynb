{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, all_sections, persist_directory='./.markdown'):\n",
    "        self.all_sections = all_sections\n",
    "        self.persist_directory = persist_directory\n",
    "        self.vectordb = None\n",
    "        \n",
    "    # Method to create and persist embeddings\n",
    "    def create_and_persist_embeddings(self):\n",
    "        # Creating an instance of OpenAIEmbeddings\n",
    "        # embedding = OpenAIEmbeddings()\n",
    "\n",
    "        embedding = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "        def split_list(input_list, chunk_size):\n",
    "            for i in range(0, len(input_list), chunk_size):\n",
    "                yield input_list[i:i + chunk_size]\n",
    "\n",
    "        split_docs_chunked = split_list(self.all_sections, 5000)\n",
    "\n",
    "        # Creating an instance of Chroma with the sections and the embeddings\n",
    "        for split_docs_chunk in split_docs_chunked:\n",
    "            self.vectordb = Chroma.from_documents(\n",
    "                documents=split_docs_chunk,\n",
    "                embedding=embedding,\n",
    "                persist_directory=self.persist_directory,\n",
    "            )\n",
    "            # Persisting the embeddings\n",
    "            self.vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import utils as chromautils\n",
    "\n",
    "class DocumentManager:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.documents = []\n",
    "        self.all_sections = []\n",
    "    \n",
    "    def load_documents(self):\n",
    "        # loader = DirectoryLoader(self.directory_path, glob=self.glob_pattern, show_progress=True, loader_cls=UnstructuredMarkdownLoader)\n",
    "        loader = UnstructuredMarkdownLoader(self.file_path, mode=\"elements\")\n",
    "        documents = loader.load()\n",
    "        self.documents = chromautils.filter_complex_metadata(documents)\n",
    "        # text_splitter = RecursiveCharacterTextSplitter(\n",
    "        #             chunk_size=10000, chunk_overlap=200, add_start_index=True\n",
    "        #     )\n",
    "        # self.documents = text_splitter.split_documents(filter_documents)\n",
    "\n",
    "    def split_documents(self):\n",
    "        for doc in self.documents:\n",
    "            self.all_sections.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising and loading documents\n",
    "doc_manager = DocumentManager('Z:/github/qachatbot/qachatbot/.markdown/5esrd.md')\n",
    "doc_manager.load_documents()\n",
    "doc_manager.split_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12933"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_manager.all_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Z:/github/qachatbot/qachatbot/.markdown/5esrd.md', 'last_modified': '2024-07-18T21:16:39', 'parent_id': '3b75181130dc6c40c6652862bc9df07f', 'filetype': 'text/markdown', 'file_directory': 'Z:/github/qachatbot/qachatbot/.markdown', 'filename': '5esrd.md', 'category': 'NarrativeText'}, page_content='Rapier. Melee Weapon Attack: +3 to hit, reach 5 ft., one target. Hit: 5 (1d8 + 1) piercing damage.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_manager.all_sections[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\venv\\qachatbot\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "z:\\venv\\qachatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Creation and persistence of embeddings\n",
    "embed_manager = EmbeddingManager(doc_manager.all_sections)\n",
    "embed_manager.create_and_persist_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'category': 'Title', 'category_depth': 0, 'file_directory': 'Z:/github/qachatbot/qachatbot/.markdown', 'filename': '5esrd.md', 'filetype': 'text/markdown', 'last_modified': '2024-07-18T21:16:39', 'source': 'Z:/github/qachatbot/qachatbot/.markdown/5esrd.md'}, page_content='Hit Dice: 1d12 per barbarian level'),\n",
       " Document(metadata={'category': 'NarrativeText', 'file_directory': 'Z:/github/qachatbot/qachatbot/.markdown', 'filename': '5esrd.md', 'filetype': 'text/markdown', 'last_modified': '2024-07-18T21:16:39', 'parent_id': '53a68f3d59e096bf768a98b9d4e0fd62', 'source': 'Z:/github/qachatbot/qachatbot/.markdown/5esrd.md'}, page_content='Hit Points at Higher Levels: 1d12 (or 7) + your Constitution\\nmodifier per barbarian level after 1st')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve\n",
    "retriever = embed_manager.vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "retrieved_docs = retriever.invoke(\"Barbarian hit dice?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"You are an assistant for question-answering tasks. \"\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \"\n",
    "                \"Use three sentences maximum and keep the answer concise. \\n\"\n",
    "                \"Context: {context} \\n\"\n",
    "                \"Question: {question} \\n\"\n",
    "                \"Answer:\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "llm = ChatOllama(model=\"phi3\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def invoke_chat(user_input: str, k=3, llm: BaseChatModel = None):\n",
    "    context = retriever.invoke(user_input, k=k)\n",
    "    context = format_docs(context)\n",
    "    message = prompt.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": user_input\n",
    "    })\n",
    "    if llm:\n",
    "        message = llm.invoke(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \\nContext: Hit Points at Higher Levels: 1d12 (or 7) + your Constitution\\nmodifier per barbarian level after 1st\\n\\nBarbarian \\nQuestion: What is Barbarian hit point? \\nAnswer:\")])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Barbarian hit point?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = invoke_chat(\"What is Barbarian hit point?\", k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The formula for a Barbarian's Hit Points at higher levels is either \"1d12 (roll to get number) + your Constitution modifier\" per barbarian level after the first. If not specified, they start with 10 HD points plus their Constitution modifier as base hit point count before any roll or additional bonuses are applied.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
